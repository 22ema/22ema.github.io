---
title: "Strength in Diversity: Multi-Branch Representation Learning for Vehicle Re-Idenfication"
categories:
  - Journal
tags:
  - ReID
published: true
comments: true
---

# Abstract.

본 논문은 차량 재식별의 성능 향상을 위해 가볍고 효율적인 multi-branch 딥러닝 구조를 설명한다.

최근 V-ReID(Vehicle ReID) 연구들은 복잡한 branch들의 조합으로 구성되어 효율적이지 못함. 

본 논문은 가볍고 간단한 모델 구조로도 기존 성능을 유지 또는 개선할 수 있다고 주장함.

특징 식별성과 다양성을 향상 시키기 위한 multi-branch 구조로 디자인 된 Loss-Branch-Split strategies와 Grouped-convolution의 합성을 제안한다.

### Loss-Branch-Split strategies

아래 두개의 branch의 결합으로 이루어짐.

- ResNet grobal branch architecture
- BotNet self-attention branch architecture

### Grouped-Convolution

본 논문에서 모델 경량화 솔루션으로 활용됨.

---

추가적으로 Camera ID 와 pose 정보들을 통해 reid 성능을 향상 시킴.

Veri-776 데이터와 Veri-Wild에서 SOTA 급 성능을 발휘함.

- Veri-776: 85.6% mAP, 97.7% CMC1
- Veri-Wild: 88.1% mAP, 96.3% CMC1


# Introduction.

![Untitled]()

위의 그림처럼 query가 들어왔을 때, Gallery 내의 동일한 ID를 찾아 반환하는 것이 Vehicle ReID의 목적 중 하나 이다. 

CNN을 사용한 V-ReID는 동일한 모델과 색상의 서로 다른 차량 또는 다른 각도에서 관찰할 때 완전히 다른 외관을 갖는 동일한 차량과 같은 클래스 간 유사성과 클래스 내 불일치로 인해 문제가 심각하다.

위의 문제를 해결하고자 본 논문에서는 여러가지 다른 표현들을 학습하여 생긴 이미지 특징들을 제안한다.

- **Improved feature diversity**:  backbone network의 여러 branch들을 사용하여 특징의 다양성을 확보함
- **Reduced overfitting**: multi branch를 사용하면 overfitting의 위험성이 줄어듬
- **Increased robustness**: multi branch를 사용하면 다양한 특징을 학습할 수 있고 다양한 입력에 대해 robust하게 결과를 출력할 수 있다.

본 연구의 4가지 contributions

1. branch 별 다른 아키텍쳐와 loss를 통해 생긴 다양한 global embedding을 생성하는 LBS 아키텍처를 사용한다.
2. self-attention을 사용하여 차량의 지역적 특성에 대한 local 종속성을 만든다.
3. LBS의 사용으로 인해 증가된 복잡성을 개선하고자 Grouped convolution 사용
4. 카메라 ID 및 차량의 pose를 효율적으로 활용함.

# Methodology

![Diagram of the proposed MBR architecture. In this figure ++ denotes concatenation.]()

Diagram of the proposed MBR architecture. In this figure ++ denotes concatenation.

### A.Multi-branch Global Embeddings

제안된 Architecture는 branch 별로 다른 구조와 loss function을 가지고 있어 여러 global embedding을 만들 수 있다.

위의 그림을 보면 global module과 attention module 2개의 main modules이 있다. 각 module에서 출력된 embedding 백터들이 결합되어 다양성이 있는 임베딩 벡터가 생성됨.

![Untitled]()

- Global Module은 Resnet50의 layer4 결과를 GAP하여 사용
- Attention Module은 BoT 모델의 Global attention embedding 결과를 사용한다.

위의 그림에서 볼 수 있듯이 각 module은 두개의 loss를 가진다. 분류와 metric loss로 나누어 분기된다.

- metric loss: feaure embeddings 의 판별력
- classification loss: 각 ID에 대한 의미론적 이해

전체 구조에서 backbone의 F1, F2, F3 layer는 서로 가중치를 공유한다. F3에서 16x16x1024 형태의 feature map이 출력된다. FN4 layer 부터 각 module에 대한 가중치를 가지고 있으며 아래의 식으로 정리된다.

![Untitled]()

1. ResNet50 Global Branch (R50): global branch는 이미지의 전체적인 형태를 인식하기 위해 사용됨. ResNet50-IBN 모델의 4번째 layer를 사용하여 branch를 만들었음.
2. Bottlenek Transformer Branch (BoT): self attention을 통해 지역적인 특징을 추출.

BoT는 4번째 resnet layer에서 bottlenet block을 수정하여 구현하였음. (코드 확인 필요)

### B. Branch Grouped Convolution

![Untitled]()

loss를 분할하는 전체적인 모델 구조에 초점을 두고 내부 convolution의 경우, ResNext에서 사용된 grouped convolution을 적용함.

위의 그림처럼 그룹별로 Convolution 연산을 수행한다.

### C. Leveraging Additional Information (LAI)

본 논문에서는 이미지의 메타데이터를 사용하기 위한 CNN을 설계하였음. 이때 메타데이터는 카메라 ID와 카메라가 보고 있는 방향을 사용함. 이유는 데이터에 쉽게 접근 가능하기 때문이다.